Simple experiment to try using an LLM of choice, a vector similarity store, and langchain to try to have conversational search with pretty messy documents. The IPCC reports have lots of great info on climate, but are thousands of pages long, filled with figures and infographics that aren't always easy to parse, and would benefit from the abiltity to easily query it. More technical details in the header section of the notebook. 

This is a bit of an exploration as to what can be achieved without paying the overhead costs of finetuning, as that isn't always available for all use cases. The major pitfall here is that while it clearly works when the query has a basis in real text of the document (so that the vector similarity search can succeed), quality starts to degrade when the query is more ambiguous or less of a clear QA with bounded expectations. In cases like this the "diffuseness" of information in the model you can get from fine-tuning on the document would probably help. We can compare this to chatclimate.ai which fine-tunes but does not use a vector store as external memory. 
